 feature extraction. These improvements not only amplify the backbone network’s ability to extract smoke-specific features but also to effectively reduce the model’s parameter count and computational complexity. A novel foreground-focused pyramid structure called a Multi-Scale Foreground- Focus Fusion Pyramid Network (MFFPN) is presented. It leverages the multi-scale feature maps extracted by the backbone network. The aforementioned feature maps are then Fire 2024, 7, 488	3 of 24 subjected to a Rectangular Self-Calibration Module (RCM) in both fused and independent forms to enhance the foreground features present within the images. The RCM employs stripe convolutions in both horizontal and vertical directions, which not only enhances the learning capability of deformable objects but also reduces the parameter count in the feature fusion section. Related Works Overview of Methods for Smoke Detection Smoke detection methods are divided into traditional vision-based smoke detection algorithms and deep learning-based smoke detection algorithms. Traditional vision-based smoke detection encompasses video-based and image-based methods. Image-based ap- proaches focus more on smoke’s color, texture, and other characteristics. Hidenori et al. [11] utilized the texture features of smoke to train an SVM for forest fire smoke recognition. H. Tian et al. [12] proposed a method to detect and separate smoke from a single image by dividing the image into quasi-smoke and quasi-background and using a dual-dictionary approach to model and separate sparse smoke. In video-based smoke detection methods, many studies rely on the motion characteristics of smoke to separate it from the background. Jia et al. [13] introduced a salient smoke detection model based on color and motion fea- tures, obtaining motion energy from video motion information to measure the saliency of suspicious smoke regions and segmenting the smoke object based on saliency. Yu et al. [14] proposed using the Lucas Kanade optical flow algorithm to calculate the optical flow of candidate regions and derived motion features from the optical flow results to distinguish smoke from other moving objects. Although video-based smoke detection can effectively extract the motion characteristics of smoke and separate it from other objects in the video, other moving objects such as swaying bags, cars driving at night, fog, or even moving people can inevitably cause false detection. Thus, it is evident that traditional Computer Vision methods typically utilize various characteristics of smoke to distinguish it from the background. Although these methods have achieved certain results in smoke detection, due to the uncertain shape and color of smoke objects and their inconspicuous features in the foreground, the manual design of feature extraction processes often contains some irra- tionalities. This results in certain deficiencies in effectively and comprehensively detecting smoke using traditional methods, whether based on static features such as smoke color and texture or dynamic features such as frequency, shape, or fluttering. Deep learning approaches based on Computer Vision, renowned for their robust feature extraction capabilities, have emerged as a promising approach in smoke detec- tion. By effectively learning the multifaceted characteristics of smoke, these methods achieve higher accuracy than traditional techniques.  Common Computer Vision tasks   in smoke detection encompass image classification, semantic segmentation, and object detection. Li et al. [15] introduced a novel framework that integrates traditional methods into Convolutional Neural Networks (CNNs) for wildfire smoke detection, specifically tailored for smoke image classification. This framework comprises a candidate smoke region segmentation strategy and a neural network architecture. The segmentation strategy removes complex backgrounds from wildfire smoke images, while dilated convolutions combined with DenseBlock enable the extraction of multi-scale features, thereby enhancing the accuracy of smoke classification. Wang et al. [16] proposed a hybrid network combining CNNs with Pyramid Gaussian Pooling (PGP) and a Transformer for smoke segmentation, achieving State-Of-The-Art (SOTA) performance that surpasses many previous segmen- tation networks. While image classification models excel in accuracy, they are limited in their ability to reflect the precise locations of smoke generation in real time. Semantic segmentation models, while capable of fine-grained image segmentation, are challenged by the ambiguous shapes of smoke, which make it difficult to annotate datasets. Furthermore, the computational demands of pixel-wise classification in semantic segmentation tasks pose practical limitations. Fire 2024, 7, 488	4 of 24 Object detection tasks aim to automatically identify and precisely locate objects of inter- est within given images or video frames. Early object detection models, such as Single Shot MultiBox Detector (SSD) [17], Region-based Convolutional Neural Network (RCNN) [18], Fast Region-based Convolutional Neural Network (Fast-RCNN) [19], and Faster Region- based Convolutional Neural Network (Faster-RCNN) [20], heavily rely on prior knowledge. For instance, SSD employs fixed anchors to predict object locations and sizes; however, anchor settings and assignment strategies often lack flexibility and Precision. R-CNN series models incur significant computational overhead in region pr